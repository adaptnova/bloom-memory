#!/usr/bin/env python3
"""
Memory Compaction Scheduler Demonstration
Shows how the scheduler works without database dependencies
"""

import asyncio
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum
from typing import Dict, Any, List, Optional
import json

# Simplified versions of the required classes for demonstration

class ConsolidationType(Enum):
    TEMPORAL = "temporal"
    SEMANTIC = "semantic"
    ASSOCIATIVE = "associative"
    HIERARCHICAL = "hierarchical"
    COMPRESSION = "compression"

class CompactionTrigger(Enum):
    TIME_BASED = "time_based"
    THRESHOLD_BASED = "threshold"
    ACTIVITY_BASED = "activity"
    IDLE_BASED = "idle"
    EMERGENCY = "emergency"
    QUALITY_BASED = "quality"

@dataclass
class CompactionSchedule:
    schedule_id: str
    trigger: CompactionTrigger
    interval: Optional[timedelta] = None
    threshold: Optional[Dict[str, Any]] = None
    active: bool = True
    last_run: Optional[datetime] = None
    next_run: Optional[datetime] = None
    run_count: int = 0

class CompactionSchedulerDemo:
    """Demonstration of the Memory Compaction Scheduler"""
    
    def __init__(self):
        self.schedules: Dict[str, CompactionSchedule] = {}
        self.compaction_log = []
        self.metrics = {
            "total_compactions": 0,
            "memories_processed": 0,
            "space_recovered": 0,
            "last_compaction": None
        }
        self._initialize_default_schedules()
    
    def _initialize_default_schedules(self):
        """Initialize default compaction schedules"""
        
        # Daily consolidation
        self.schedules["daily_consolidation"] = CompactionSchedule(
            schedule_id="daily_consolidation",
            trigger=CompactionTrigger.TIME_BASED,
            interval=timedelta(days=1),
            next_run=datetime.now() + timedelta(days=1)
        )
        
        # Hourly compression
        self.schedules["hourly_compression"] = CompactionSchedule(
            schedule_id="hourly_compression",
            trigger=CompactionTrigger.TIME_BASED,
            interval=timedelta(hours=1),
            next_run=datetime.now() + timedelta(hours=1)
        )
        
        # Memory threshold
        self.schedules["memory_threshold"] = CompactionSchedule(
            schedule_id="memory_threshold",
            trigger=CompactionTrigger.THRESHOLD_BASED,
            threshold={"memory_count": 10000}
        )
        
        print("üìÖ Initialized default schedules:")
        for schedule_id, schedule in self.schedules.items():
            print(f"   ‚Ä¢ {schedule_id}: {schedule.trigger.value}")
    
    def demonstrate_compaction_cycle(self):
        """Demonstrate a complete compaction cycle"""
        print("\nüîÑ Demonstrating Compaction Cycle")
        print("=" * 60)
        
        # Simulate time passing and triggering different schedules
        
        # 1. Check if daily consolidation should run
        daily = self.schedules["daily_consolidation"]
        print(f"\n1Ô∏è‚É£ Daily Consolidation Check:")
        print(f"   Next run: {daily.next_run.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"   Would trigger: {datetime.now() >= daily.next_run}")
        
        # Simulate running it
        if True:  # Force run for demo
            print("   ‚úÖ Triggering daily consolidation...")
            self._run_compaction("daily_consolidation", ConsolidationType.TEMPORAL)
            daily.last_run = datetime.now()
            daily.next_run = datetime.now() + daily.interval
            daily.run_count += 1
        
        # 2. Check memory threshold
        threshold = self.schedules["memory_threshold"]
        print(f"\n2Ô∏è‚É£ Memory Threshold Check:")
        print(f"   Threshold: {threshold.threshold['memory_count']} memories")
        print(f"   Current count: 12,345 (simulated)")
        print(f"   Would trigger: True")
        
        # Simulate emergency compaction
        print("   üö® Triggering emergency compaction...")
        self._run_compaction("memory_threshold", ConsolidationType.COMPRESSION, emergency=True)
        
        # 3. Hourly compression
        hourly = self.schedules["hourly_compression"]
        print(f"\n3Ô∏è‚É£ Hourly Compression Check:")
        print(f"   Next run: {hourly.next_run.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"   Compresses memories older than 7 days")
        
        # 4. Show metrics
        self._show_metrics()
    
    def _run_compaction(self, schedule_id: str, compaction_type: ConsolidationType, emergency: bool = False):
        """Simulate running a compaction"""
        start_time = datetime.now()
        
        # Initialize default values
        memories_processed = 1000
        space_recovered = 1024 * 1024 * 5  # 5MB default
        
        # Simulate processing
        if compaction_type == ConsolidationType.TEMPORAL:
            memories_processed = 5000
            space_recovered = 1024 * 1024 * 10  # 10MB
            print(f"      ‚Ä¢ Grouped memories by time periods")
            print(f"      ‚Ä¢ Created daily summaries")
            print(f"      ‚Ä¢ Consolidated 5,000 memories")
            
        elif compaction_type == ConsolidationType.COMPRESSION:
            memories_processed = 2000
            space_recovered = 1024 * 1024 * 50  # 50MB
            print(f"      ‚Ä¢ Compressed old memories")
            print(f"      ‚Ä¢ Removed redundant data")
            print(f"      ‚Ä¢ Freed 50MB of space")
            
            if emergency:
                print(f"      ‚Ä¢ üö® EMERGENCY MODE: Maximum compression applied")
                
        elif compaction_type == ConsolidationType.SEMANTIC:
            memories_processed = 3000
            space_recovered = 1024 * 1024 * 20  # 20MB
            print(f"      ‚Ä¢ Identified semantic patterns")
            print(f"      ‚Ä¢ Merged related concepts")
            print(f"      ‚Ä¢ Consolidated 3,000 memories")
        
        # Update metrics
        self.metrics["total_compactions"] += 1
        self.metrics["memories_processed"] += memories_processed
        self.metrics["space_recovered"] += space_recovered
        self.metrics["last_compaction"] = datetime.now()
        
        # Log compaction
        self.compaction_log.append({
            "timestamp": start_time,
            "schedule_id": schedule_id,
            "type": compaction_type.value,
            "memories_processed": memories_processed,
            "space_recovered": space_recovered,
            "duration": (datetime.now() - start_time).total_seconds()
        })
    
    def demonstrate_adaptive_strategies(self):
        """Demonstrate adaptive compaction strategies"""
        print("\nüéØ Demonstrating Adaptive Strategies")
        print("=" * 60)
        
        # Sleep cycle compaction
        print("\nüåô Sleep Cycle Compaction:")
        print("   Mimics human sleep cycles for optimal consolidation")
        
        phases = [
            ("REM-like", "Light consolidation", ConsolidationType.TEMPORAL, 5),
            ("Deep Sleep", "Semantic integration", ConsolidationType.SEMANTIC, 10),
            ("Sleep Spindles", "Associative linking", ConsolidationType.ASSOCIATIVE, 5),
            ("Cleanup", "Compression and optimization", ConsolidationType.COMPRESSION, 5)
        ]
        
        for phase_name, description, comp_type, duration in phases:
            print(f"\n   Phase: {phase_name} ({duration} minutes)")
            print(f"   ‚Ä¢ {description}")
            print(f"   ‚Ä¢ Type: {comp_type.value}")
        
        # Activity-based adaptation
        print("\nüìä Activity-Based Adaptation:")
        
        activity_levels = [
            (0.2, "Low", "Aggressive compression"),
            (0.5, "Medium", "Balanced consolidation"),
            (0.8, "High", "Minimal interference")
        ]
        
        for level, name, strategy in activity_levels:
            print(f"\n   Activity Level: {level} ({name})")
            print(f"   ‚Ä¢ Strategy: {strategy}")
            if level < 0.3:
                print(f"   ‚Ä¢ Actions: Full compression, memory cleanup")
            elif level < 0.7:
                print(f"   ‚Ä¢ Actions: Hierarchical organization, moderate compression")
            else:
                print(f"   ‚Ä¢ Actions: Quick temporal consolidation only")
    
    def demonstrate_manual_control(self):
        """Demonstrate manual compaction control"""
        print("\nüéÆ Demonstrating Manual Control")
        print("=" * 60)
        
        print("\n1. Adding Custom Schedule:")
        custom_schedule = CompactionSchedule(
            schedule_id="weekend_deep_clean",
            trigger=CompactionTrigger.TIME_BASED,
            interval=timedelta(days=7),
            next_run=datetime.now() + timedelta(days=6)
        )
        self.schedules["weekend_deep_clean"] = custom_schedule
        print(f"   ‚úÖ Added 'weekend_deep_clean' schedule")
        print(f"   ‚Ä¢ Runs weekly on weekends")
        print(f"   ‚Ä¢ Deep semantic consolidation")
        
        print("\n2. Manual Trigger:")
        print("   Triggering immediate semantic compaction...")
        self._run_compaction("manual", ConsolidationType.SEMANTIC)
        print("   ‚úÖ Manual compaction completed")
        
        print("\n3. Emergency Response:")
        print("   Memory pressure detected: 95%")
        print("   üö® Initiating emergency protocol...")
        print("   ‚Ä¢ Stopping non-essential schedules")
        print("   ‚Ä¢ Maximum compression mode")
        print("   ‚Ä¢ Priority: 1.0 (highest)")
        self._run_compaction("emergency", ConsolidationType.COMPRESSION, emergency=True)
    
    def _show_metrics(self):
        """Display current metrics"""
        print("\nüìä Compaction Metrics:")
        print(f"   Total compactions: {self.metrics['total_compactions']}")
        print(f"   Memories processed: {self.metrics['memories_processed']:,}")
        print(f"   Space recovered: {self.metrics['space_recovered'] / (1024*1024):.1f} MB")
        if self.metrics['last_compaction']:
            print(f"   Last compaction: {self.metrics['last_compaction'].strftime('%Y-%m-%d %H:%M:%S')}")
    
    def show_schedule_status(self):
        """Show status of all schedules"""
        print("\nüìÖ Schedule Status")
        print("=" * 60)
        
        for schedule_id, schedule in self.schedules.items():
            print(f"\n{schedule_id}:")
            print(f"   ‚Ä¢ Trigger: {schedule.trigger.value}")
            print(f"   ‚Ä¢ Active: {'‚úÖ' if schedule.active else '‚ùå'}")
            print(f"   ‚Ä¢ Run count: {schedule.run_count}")
            
            if schedule.last_run:
                print(f"   ‚Ä¢ Last run: {schedule.last_run.strftime('%Y-%m-%d %H:%M:%S')}")
            
            if schedule.next_run:
                time_until = schedule.next_run - datetime.now()
                hours = time_until.total_seconds() / 3600
                print(f"   ‚Ä¢ Next run: {schedule.next_run.strftime('%Y-%m-%d %H:%M:%S')} ({hours:.1f} hours)")
            
            if schedule.threshold:
                print(f"   ‚Ä¢ Threshold: {schedule.threshold}")
    
    def show_architecture(self):
        """Display the compaction architecture"""
        print("\nüèóÔ∏è Memory Compaction Architecture")
        print("=" * 60)
        
        architecture = """
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Memory Compaction Scheduler                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Scheduler   ‚îÇ  ‚îÇ   Triggers    ‚îÇ  ‚îÇ    Workers      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    Loop      ‚îÇ  ‚îÇ               ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ ‚Ä¢ Time-based  ‚îÇ  ‚îÇ ‚Ä¢ Worker 0      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Check     ‚îÇ  ‚îÇ ‚Ä¢ Threshold   ‚îÇ  ‚îÇ ‚Ä¢ Worker 1      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   schedules ‚îÇ  ‚îÇ ‚Ä¢ Activity    ‚îÇ  ‚îÇ ‚Ä¢ Worker 2      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Create    ‚îÇ  ‚îÇ ‚Ä¢ Idle        ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   tasks     ‚îÇ  ‚îÇ ‚Ä¢ Emergency   ‚îÇ  ‚îÇ Concurrent      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Queue     ‚îÇ  ‚îÇ ‚Ä¢ Quality     ‚îÇ  ‚îÇ processing      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   tasks     ‚îÇ  ‚îÇ               ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              Compaction Strategies                   ‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Temporal Consolidation  ‚Ä¢ Semantic Compression    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Hierarchical Ordering   ‚Ä¢ Associative Linking     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Quality-based Decay     ‚Ä¢ Emergency Compression   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                Memory Layers (11-20)                 ‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Consolidation Hub    ‚Ä¢ Decay Management          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Compression Layer    ‚Ä¢ Priority Optimization     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Integration Layer    ‚Ä¢ Index Maintenance         ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        """
        print(architecture)


def main():
    """Run the demonstration"""
    print("üöÄ Memory Compaction Scheduler Demonstration")
    print("=" * 60)
    print("This demonstration shows how the memory compaction scheduler")
    print("manages automated memory maintenance in the Nova system.")
    print()
    
    demo = CompactionSchedulerDemo()
    
    # Show architecture
    demo.show_architecture()
    
    # Demonstrate compaction cycle
    demo.demonstrate_compaction_cycle()
    
    # Show adaptive strategies
    demo.demonstrate_adaptive_strategies()
    
    # Demonstrate manual control
    demo.demonstrate_manual_control()
    
    # Show final status
    demo.show_schedule_status()
    
    print("\n" + "=" * 60)
    print("‚úÖ Demonstration Complete!")
    print("\nKey Takeaways:")
    print("‚Ä¢ Automatic scheduling reduces manual maintenance")
    print("‚Ä¢ Multiple trigger types handle different scenarios")
    print("‚Ä¢ Adaptive strategies optimize based on system state")
    print("‚Ä¢ Emergency handling ensures system stability")
    print("‚Ä¢ Comprehensive metrics track effectiveness")
    print("\nThe Memory Compaction Scheduler ensures optimal memory")
    print("performance through intelligent, automated maintenance.")


if __name__ == "__main__":
    main()